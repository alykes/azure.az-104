# Storage Account Overview

Storage Accounts only belong to a single subscription
The storage account name needs to be globally unique
The Storage Account name is also part of the endpoint URL
The Storage Account is deployed to a specific region
Pricing differences based on the region it is located in
Put the data in the same region as the application or the users
You need to take note of an governance and compliance requirements

## Creating a Storage Account  

You can a choice of:

- **Standard** - Most scenarios use this type
- **Premium** - more expensive and used for lower latency

**LRS** - Locally redundant storage makes 3 copies of your data in the same region. Non critical scenarios
**ZRS** - Data remains in the same region, geographically distributed and therefore physically distributed. Highly available scenarios
**GRS** - Puts data into a secondary region, therefore you will get 6 copies of your data; 3 in each region. Backup scenarios
**ZGRS** - Combines GRS and ZRS. Recommended for critical data scenarios

If you select GRS and select **Make read access to data available in the event of regional unavailability**, you can use a read only link if the region goes down.

> **Exam Tip:** May ask you what the cheapest option would be for a particular scenario.

There are different types of storage tiers:

Hot - The cheapest
Cool - For data that isn't accessed frequently
Archive - For data backup purposes; set on file by file basis, expensive and takes a long time to retrieve

You pay for reads and writes

## Advanced Options  

There are a few sections here:  

- Security
  - Require secure transfer for REST API - sometimes you might not have an application that doesn't support encryption. I wouldn't recommend turning this off.
  - Enabling public access on containers - So you can allow public access to your container. Again, this isn't recommended.
  - Enable storage account key access - Claims based, more flexible. You can also use Azure Entra ID and RBAC instead of account keys, which is more secure.
  - Minimum TLS version - Should really be set to 1.2. Definitely not recommended to use lower versions.
- Data Lake Storage Gen2
  - Use it for hadoop, Azure Analytics, large data sections.
- Blob Storage
  - **Hot** - The cheapest, day to day usage. The default.
  - **Cool** - For data that isn't accessed frequently, such as backups.
  - Supports up to 5PB
- Azure Files
  - Supports file shares up to a maximum of 100TiB

## Public vs Private Networking

- Enable public access from all networks - By default all storage accounts are accessible on the internet and through all networks within Azure. If you have the storage account keys, then there is an endpoint that you can use to access the data.
- Enable Public Access from selected vnet and public IPs - You can also specify exactly which virtual networks and IP addresses can access the storage account.
- Disable public access and use private access - Finally, you can disable access entirely and use a private endpoint of a private link. You need to set this up on both ends, the storage account and from where you would like to access it.

Network routing can either be through:

- The Microsoft network
- The Public Internet

## Data Protection

- Recovery - Protect data from accidental or erroneous deletion
  - Point in Time restore for containers - it enables, versioning, change feed and blob soft-delete
  - Soft delete - you can retain blobs, containers and files shares for "n" days
- Tracking - Manage versions and keep track of changes made to blob data
  - Enable versioning for blobs
  - Enable blob change feed - keep track of create, modify and delete changes to blobs in the storage account
- Access Control
  - Enable version-level immutability support, basically a file cannot be modified or deleted, good to use for auditing logs
  
## Encryption

Data is encrypted by default. There are two types of encryption:

- **Microsoft Managed Keys (MMK)** - MS handles the keys, this is the default
- **Customer Managed Keys (CMK)** - You handle and manage the keys, usually done for governance and compliance.
  - If you choose CMK, you will have to choose a Keyvault, the encryption key and utilise a Managed Identity.
- **Enable Support for CMK** - Blobs and files only | All service types - **Note:** this setting can't be changed after creation of the storage account.
- **Enable Infrastructure Encryption** - 2nd layer of encryption at the hardware layer

## Storage Account creation

- **Tags** - Are pretty important when it comes to resources in Azure  
- You can "download a template for automation" on the review page when you are about to deploy a resource

> Creating a storage account is free, you only pay for the costs that you incur when using the storage account.

## Blobs, Files, Queues and Tables

When you create a storage account, it can contain one of each of the following:

- Containers - Blob storage, just like AWS Buckets. There are no folders, sub-folders. Everything is in a container, they are all objects (like in AWS). It is CBAC by default. If you upload a file and copy the URL, you won't be able to simply access the file without using a token.
- File Shares - Traditional Windows File Share options, it is a publicly shareable file share. It uses the SMB protocol (it is blocked across most of the internet). The structure is that of a traditional Windows File Server. If you select the **Connect** button, you can grab a powershell script to map the file share to your VM.
- Queues - A messaging service queue, messaging system between two applications.
- Tables - Storing table in a semi-structured manner in the storage account. You create the table and then you add data to it in the form of `PartitionKey | Value` `RowKey | Value` and add more entities as required. It's sort of like an excel spreadsheet.
  
> You can assign separate permissions on each of the these storage types individually.
> Queues and Tables are not on the Exam

## Access Keys and SAS

Under the **Security + Networking** section, there is an **Access Keys** area that you can go through to find the access keys

### Keys

- Anyone with either of the keys can connect to the storage account over the network and use it to authenticate into it.
- It's a good idea to Set a rotation reminder to and you can switch keys to allow continuous access.

### Shared Access Signature

- This is another way to grant access to the storage account, it uses the key to access the storage account but you can assign specific permissions.
- It is linked to either key 1 or key 2
- Once you have set permissions, you generate the SAS token
- To use the SAS token, append it to the end of the file you are trying to access (e.g., in the browser)
- **You can't revoke an SAS** the only way to stop a SAS being used is to rotate the key that the SAS is based on
- SAS can also be created at the file level (through the ellipsis), so it can be granular

### Stored Access Policy  

- This is another method to control access to files
- **Policies can be revoked**
- Select a container, then click the ellipsis, then select **Access Policy**
  - You will see two sections; Stored Access Policies and Immutable Blob storage (Legal hold, Time based retention)
  - Click Add Policy and you can set a condition on the SAS. Then you select a Start time and an Expiry time
  - Now when you want to generate an SAS, you can select the Stored Access Policy to apply to your storage
  - This is a safer method than sharing a SAS token alone.
  - You can delete the Access Policy from the container, which revokes access immediately

## Redundant Storage

There are different types of storage

- **Locally Redundant Storage (LRS)** - There are 3 total copies in the local region
- **Geo-redundant Storage (GRS)** - There are copies of the data in another region, it is now in two regions
  - You can check the secondary region by going into **Geo-replication**
  - You can click the button to **Prepare for failover** if you would like to move access to the other region
    - If you do failover, then the storage becomes LRS and you need to select GRS again to enable that capability
- **Read-access Geo-redundant Storage (RA-GRS)** - This will also give you access to the read only copy of the data

## Access tiers

These are different types of performance:

- **Standard** - Recommended for most scenarios (general purpose v2 account)
  - For Blob storage there are two types of **Access tiers** that you can set as default:
    - **Hot** - frequently accessed data and day-to-day usage scenarios
    - **Cool** - Infrequently accessed data and backup scenarios (cheaper writes / expensive reads)
  - These tiers can be changed even after you create the storage account
  - The tiers, can be changed on a per file basis and therefore allows you granular control, you can select:
    - **Hot** - frequently accessed data and day-to-day usage scenarios
    - **Cool** - Infrequently accessed data and backup scenarios (cheaper writes / expensive reads), charged at 30 days of storage minimum
    - **Cold** - Even less frequently accessed data than Cool.
    - **Archive** - Makes the blob inaccessible until it is rehydrates back to "Hot" or "Cool", which can take several hours.
- **Premium** - Recommended for low-latency and only supports Block blobs, File Shares, Page blobs (not Tables or Queues)
- Costs are based on tier type and operation (Read/Write)

## EntraID Access Control for Storage Accounts

Instead of using Access Keys, you can use EntraID authentication. To use this, it's best practise to **disable** storage account key access in **settings** -> **configuration** on the storage account. Once you have done this, you can click on **Default to Microsoft EntraID authorisation in the Azure Portal**.

To manage access to the storage account:

- click on **Access Control (IAM)**
- Add **Role Assignment**
- Select the role that related to the storage account permissions that you would like the user(s) to have
- Select members or a group
- You can add role assignment conditions to filter  based on specific conditions, like trying to access a private container. You can deny this action
- Click **Review and Assign**

## Azure File Shares Soft Delete

Enabled is the default option. You can also set the number of days to retain the file.

You can enable this on:

- blobs
- containers
- file shares

To retrospectively change this setting, you can go to the storage account and select **Data Management** -> **Data Protection**.  
> When you enable soft delete settings for a file share, a Backup Service is enabled automatically. A Recovery Services Vault (RSV) is created to support this function. A lock is also placed on the file share. If you delete the file share, after removing the lock, it will remain in soft delete for the period you specified. You can view deleted shares by click on the **Show deleted shares** slider. (You can then un-delete the shares, if desired)

## Azure File Shares Snapshots

In the file share, there are two options under **Operations**:

- **Snapshots** - A point in time backup of the fileshare. This allows you to go into the snapshot and download/restore specific files from a snapshot. You can also share a URL to a file in the snapshot. Snapshots never expire, you need to delete it.
- **Backup** - Runs on a schedule, setting are in a backup policy. You can kick off backups manually.

## Azure Blob Storage versioning

You can turn on versioning during the creation of the storage account or retrospectively for the Blob. You can take a look at more of the settings for data protection in **Data Management** -> **Data Protection**.  

- Every time you write a blob into a storage account, it is given a version number.
- You can keep all versions or delete them after *n* days (lifecycle management)
- Microsoft recommends that you don't have more than 1000 versions of the file as it slows down operations
- To access the versions of the file, click on the **ellipsis** -> **Properties** -> **Versions** tab
  - You can then download the file, make is the current version or create a SAS token to access it
- **Lifecycle Management**, which can be found under Data Management
  - Create a rule specifically for file version to move it to a different storage type based on the age of the file

## HANDS-ON LAB: Storage

[Manage Storage](https://github.com/MicrosoftLearning/AZ-104-MicrosoftAzureAdministrator/blob/master/Instructions/Labs/LAB_07-Manage_Azure_Storage.md)
